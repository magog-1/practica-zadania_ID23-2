{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data\\\\preprocessed_descriptions.csv')\n",
    "res = ''\n",
    "for i in data['preprocessed_descriptions'][data['preprocessed_descriptions'].isna() == False]:\n",
    "    res += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alvarez', 'guthrie', '2009this', ..., 'comanother', 'apricot',\n",
       "       'gratinhaven'], dtype='<U30')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_words = np.array(list(set(nltk.word_tokenize(res))))\n",
    "uni_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('siamese', 'color'),\n",
       " ('teddy', 'frequently'),\n",
       " ('mineral', '400ml'),\n",
       " ('mancini', 'gloves'),\n",
       " ('sur', 'wayyy')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(np.random.choice(uni_words), np.random.choice(uni_words)) for _ in range(5)]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8, 6, 7, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance(pairs[0][0], pairs[0][1]), nltk.edit_distance(pairs[1][0], pairs[1][1]), nltk.edit_distance(pairs[2][0], pairs[2][1]), nltk.edit_distance(pairs[3][0], pairs[3][1]), nltk.edit_distance(pairs[4][0], pairs[4][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clotted',\n",
       " 'blotted',\n",
       " 'spotted',\n",
       " 'bloated',\n",
       " 'potted',\n",
       " 'shouted',\n",
       " 'jotted',\n",
       " 'sorted',\n",
       " 'dotted',\n",
       " 'allotted']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_e_distance(word, k):\n",
    "    mn = 1\n",
    "    res = []\n",
    "    while True:\n",
    "        for i in uni_words:\n",
    "            if nltk.edit_distance(word, i) == mn:\n",
    "                res.append(i)\n",
    "            if len(res) == k:\n",
    "                return res\n",
    "        mn += 1\n",
    "\n",
    "word_e_distance('slotted', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade',\n",
       " 'grate',\n",
       " 'grapes',\n",
       " 'grace',\n",
       " 'grave',\n",
       " 'gale',\n",
       " 'gravy',\n",
       " 'craze',\n",
       " 'grams',\n",
       " 'gate']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_e_distance('grape', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alvarez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guthrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>robust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23885</th>\n",
       "      <td>hopeful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23886</th>\n",
       "      <td>recpie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23887</th>\n",
       "      <td>comanother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23888</th>\n",
       "      <td>apricot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23889</th>\n",
       "      <td>gratinhaven</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23890 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word\n",
       "0          alvarez\n",
       "1          guthrie\n",
       "2         2009this\n",
       "3             utah\n",
       "4           robust\n",
       "...            ...\n",
       "23885      hopeful\n",
       "23886       recpie\n",
       "23887   comanother\n",
       "23888      apricot\n",
       "23889  gratinhaven\n",
       "\n",
       "[23890 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2_1 = pd.DataFrame({'word':uni_words})\n",
    "df_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word               257241\n",
       "stemmed_word       257241\n",
       "normalized_word    257241\n",
       "Name: 56, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "df_2_1['stemmed_word'] = df_2_1['word'].apply(lambda x: stemmer.stem(x))\n",
    "\n",
    "lemmer = nltk.WordNetLemmatizer()\n",
    "df_2_1['normalized_word'] = df_2_1['word'].apply(lambda x: lemmer.lemmatize(x))\n",
    "                                                 \n",
    "df_2_1.iloc[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>pit</td>\n",
       "      <td>pit</td>\n",
       "      <td>pit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>fussed</td>\n",
       "      <td>fuss</td>\n",
       "      <td>fussed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>jackie</td>\n",
       "      <td>jacki</td>\n",
       "      <td>jackie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>care</td>\n",
       "      <td>care</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>laguna2001</td>\n",
       "      <td>laguna2001</td>\n",
       "      <td>laguna2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>stoppingly</td>\n",
       "      <td>stop</td>\n",
       "      <td>stoppingly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>mulit</td>\n",
       "      <td>mulit</td>\n",
       "      <td>mulit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>acelgas</td>\n",
       "      <td>acelga</td>\n",
       "      <td>acelgas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>zwteven</td>\n",
       "      <td>zwteven</td>\n",
       "      <td>zwteven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>ovenproof</td>\n",
       "      <td>ovenproof</td>\n",
       "      <td>ovenproof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>zwt8</td>\n",
       "      <td>zwt8</td>\n",
       "      <td>zwt8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>satisfies</td>\n",
       "      <td>satisfi</td>\n",
       "      <td>satisfies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ethel</td>\n",
       "      <td>ethel</td>\n",
       "      <td>ethel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>cathy</td>\n",
       "      <td>cathi</td>\n",
       "      <td>cathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>bluegill</td>\n",
       "      <td>bluegil</td>\n",
       "      <td>bluegill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>kerr</td>\n",
       "      <td>kerr</td>\n",
       "      <td>kerr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>beth</td>\n",
       "      <td>beth</td>\n",
       "      <td>beth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>rolled</td>\n",
       "      <td>roll</td>\n",
       "      <td>rolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ritter</td>\n",
       "      <td>ritter</td>\n",
       "      <td>ritter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>leaving</td>\n",
       "      <td>leav</td>\n",
       "      <td>leaving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>joan</td>\n",
       "      <td>joan</td>\n",
       "      <td>joan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>waiting</td>\n",
       "      <td>wait</td>\n",
       "      <td>waiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>jill</td>\n",
       "      <td>jill</td>\n",
       "      <td>jill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>journalthis</td>\n",
       "      <td>journalthi</td>\n",
       "      <td>journalthis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>away</td>\n",
       "      <td>away</td>\n",
       "      <td>away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>unbleached</td>\n",
       "      <td>unbleach</td>\n",
       "      <td>unbleached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>loosing</td>\n",
       "      <td>loos</td>\n",
       "      <td>loosing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>cherish</td>\n",
       "      <td>cherish</td>\n",
       "      <td>cherish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>seldom</td>\n",
       "      <td>seldom</td>\n",
       "      <td>seldom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>fruitcakes</td>\n",
       "      <td>fruitcak</td>\n",
       "      <td>fruitcake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>mix</td>\n",
       "      <td>mix</td>\n",
       "      <td>mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>lehnhoff</td>\n",
       "      <td>lehnhoff</td>\n",
       "      <td>lehnhoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>worldposted</td>\n",
       "      <td>worldpost</td>\n",
       "      <td>worldposted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>processing</td>\n",
       "      <td>process</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>balm</td>\n",
       "      <td>balm</td>\n",
       "      <td>balm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>laurel</td>\n",
       "      <td>laurel</td>\n",
       "      <td>laurel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>holes</td>\n",
       "      <td>hole</td>\n",
       "      <td>hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>handyman</td>\n",
       "      <td>handyman</td>\n",
       "      <td>handyman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>our</td>\n",
       "      <td>our</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>liz</td>\n",
       "      <td>liz</td>\n",
       "      <td>liz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>toastfrom</td>\n",
       "      <td>toastfrom</td>\n",
       "      <td>toastfrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>delwyncole</td>\n",
       "      <td>delwyncol</td>\n",
       "      <td>delwyncole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>stood</td>\n",
       "      <td>stood</td>\n",
       "      <td>stood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>everthis</td>\n",
       "      <td>everthi</td>\n",
       "      <td>everthis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>fay</td>\n",
       "      <td>fay</td>\n",
       "      <td>fay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word stemmed_word normalized_word\n",
       "151          pit          pit             pit\n",
       "152       fussed         fuss          fussed\n",
       "153       jackie        jacki          jackie\n",
       "154         care         care            care\n",
       "155   laguna2001   laguna2001      laguna2001\n",
       "156   stoppingly         stop      stoppingly\n",
       "157        mulit        mulit           mulit\n",
       "158      acelgas       acelga         acelgas\n",
       "159      zwteven      zwteven         zwteven\n",
       "160    ovenproof    ovenproof       ovenproof\n",
       "161         zwt8         zwt8            zwt8\n",
       "162    satisfies      satisfi       satisfies\n",
       "163        ethel        ethel           ethel\n",
       "164        cathy        cathi           cathy\n",
       "165     bluegill      bluegil        bluegill\n",
       "166         kerr         kerr            kerr\n",
       "167         beth         beth            beth\n",
       "168         auto         auto            auto\n",
       "169       rolled         roll          rolled\n",
       "170          125          125             125\n",
       "171       ritter       ritter          ritter\n",
       "172      leaving         leav         leaving\n",
       "173         joan         joan            joan\n",
       "174      waiting         wait         waiting\n",
       "175         jill         jill            jill\n",
       "176  journalthis   journalthi     journalthis\n",
       "177         away         away            away\n",
       "178   unbleached     unbleach      unbleached\n",
       "179      loosing         loos         loosing\n",
       "180      cherish      cherish         cherish\n",
       "181       seldom       seldom          seldom\n",
       "182   fruitcakes     fruitcak       fruitcake\n",
       "183          mix          mix             mix\n",
       "184     lehnhoff     lehnhoff        lehnhoff\n",
       "185  afghanistan  afghanistan     afghanistan\n",
       "186  worldposted    worldpost     worldposted\n",
       "187   processing      process      processing\n",
       "188         balm         balm            balm\n",
       "189       laurel       laurel          laurel\n",
       "190        holes         hole            hole\n",
       "191     handyman     handyman        handyman\n",
       "192          our          our             our\n",
       "193          liz          liz             liz\n",
       "194    toastfrom    toastfrom       toastfrom\n",
       "195   delwyncole    delwyncol      delwyncole\n",
       "196        stood        stood           stood\n",
       "197     everthis      everthi        everthis\n",
       "198           un           un              un\n",
       "199          fay          fay             fay"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2_1.iloc[151:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941422</th>\n",
       "      <td>supposed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941423</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941424</th>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941425</th>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941426</th>\n",
       "      <td>theirs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>941427 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           words\n",
       "0             an\n",
       "1       original\n",
       "2         recipe\n",
       "3        created\n",
       "4             by\n",
       "...          ...\n",
       "941422  supposed\n",
       "941423        to\n",
       "941424        be\n",
       "941425      like\n",
       "941426    theirs\n",
       "\n",
       "[941427 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.DataFrame({'words': np.array(nltk.word_tokenize(res))})\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words\n",
       "the         33778\n",
       "a           30457\n",
       "and         26216\n",
       "i           23747\n",
       "this        23451\n",
       "            ...  \n",
       "jadhav          1\n",
       "jaffles         1\n",
       "jaffreys        1\n",
       "jagged          1\n",
       "zzar            1\n",
       "Name: words, Length: 23890, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_used = words.groupby('words')['words'].count()\n",
    "most_used = most_used.sort_values(ascending=False)\n",
    "most_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "cln_words = pd.DataFrame({'words': most_used.index, 'n_used': most_used.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>n_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>recipe</td>\n",
       "      <td>13210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>make</td>\n",
       "      <td>5540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>time</td>\n",
       "      <td>4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>great</td>\n",
       "      <td>4035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>use</td>\n",
       "      <td>3876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23885</th>\n",
       "      <td>jadhav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23886</th>\n",
       "      <td>jaffles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23887</th>\n",
       "      <td>jaffreys</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23888</th>\n",
       "      <td>jagged</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23889</th>\n",
       "      <td>zzar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23742 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          words  n_used\n",
       "10       recipe   13210\n",
       "20         make    5540\n",
       "27         time    4525\n",
       "30        great    4035\n",
       "31          use    3876\n",
       "...         ...     ...\n",
       "23885    jadhav       1\n",
       "23886   jaffles       1\n",
       "23887  jaffreys       1\n",
       "23888    jagged       1\n",
       "23889      zzar       1\n",
       "\n",
       "[23742 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cln_words = cln_words[cln_words['words'].isin(stop_words) == False]\n",
    "cln_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32385    this is a great dressing to serve over greens ...\n",
       "9921     a simple  but elegant chicken salad   kids lik...\n",
       "13269    a really good traditional mennonite dish  eat ...\n",
       "10554    an easy breakfast or brunch dish that can be p...\n",
       "28482             a simple recipe for cajun flavored nuts \n",
       "Name: preprocessed_descriptions, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_smpl = data['preprocessed_descriptions'].sample(5)\n",
    "data_smpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25036997, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20199692, 0.        , 0.        , 0.        , 0.25036997,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.25036997,\n",
       "        0.        , 0.        , 0.25036997, 0.25036997, 0.        ,\n",
       "        0.25036997, 0.25036997, 0.25036997, 0.25036997, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.25036997, 0.        ,\n",
       "        0.        , 0.        , 0.25036997, 0.        , 0.        ,\n",
       "        0.        , 0.20199692, 0.25036997, 0.        , 0.        ,\n",
       "        0.20199692, 0.        , 0.25036997, 0.25036997, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.35460217, 0.        , 0.        ,\n",
       "        0.28609079, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.35460217, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.35460217,\n",
       "        0.35460217, 0.35460217, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.28609079, 0.        , 0.28609079, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.35460217,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.26771341, 0.21598949, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26771341, 0.26771341, 0.21598949, 0.        ,\n",
       "        0.        , 0.26771341, 0.26771341, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26771341,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.26771341, 0.        , 0.        ,\n",
       "        0.        , 0.21598949, 0.        , 0.        , 0.26771341,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26771341,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.26771341, 0.26771341, 0.26771341],\n",
       "       [0.        , 0.29356375, 0.        , 0.23684538, 0.29356375,\n",
       "        0.29356375, 0.29356375, 0.        , 0.        , 0.29356375,\n",
       "        0.        , 0.        , 0.        , 0.23684538, 0.        ,\n",
       "        0.29356375, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29356375,\n",
       "        0.        , 0.23684538, 0.        , 0.29356375, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23684538, 0.29356375, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.42066906, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42066906, 0.42066906, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42066906, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42066906, 0.        , 0.        , 0.33939315, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "corpus_tv = vectorizer.fit_transform(data_smpl)\n",
    "corpus_tv.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844210823417489"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.spatial.distance.cosine(corpus_tv.toarray()[0], corpus_tv.toarray()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.spatial.distance.cosine(corpus_tv.toarray()[2], corpus_tv.toarray()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8465316592481439"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.spatial.distance.cosine(corpus_tv.toarray()[2], corpus_tv.toarray()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9029027445476215"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.spatial.distance.cosine(corpus_tv.toarray()[4], corpus_tv.toarray()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_3_2 = pd.DataFrame({1:[scipy.spatial.distance.cosine(corpus_tv.toarray()[0], corpus_tv.toarray()[0]), scipy.spatial.distance.cosine(corpus_tv.toarray()[0], corpus_tv.toarray()[1]),\n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[0], corpus_tv.toarray()[2]), scipy.spatial.distance.cosine(corpus_tv.toarray()[0], corpus_tv.toarray()[3]), \n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[0], corpus_tv.toarray()[4])], 2:[scipy.spatial.distance.cosine(corpus_tv.toarray()[1], corpus_tv.toarray()[0]), \n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[1], corpus_tv.toarray()[1]),\n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[1], corpus_tv.toarray()[2]), scipy.spatial.distance.cosine(corpus_tv.toarray()[1], corpus_tv.toarray()[3]), \n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[1], corpus_tv.toarray()[4])], 3:[scipy.spatial.distance.cosine(corpus_tv.toarray()[2], corpus_tv.toarray()[0]), \n",
    "                           scipy.spatial.distance.cosine(corpus_tv.toarray()[2], corpus_tv.toarray()[1]),\n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[2], corpus_tv.toarray()[2]), scipy.spatial.distance.cosine(corpus_tv.toarray()[2], corpus_tv.toarray()[3]), \n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[2], corpus_tv.toarray()[4])], 4:[scipy.spatial.distance.cosine(corpus_tv.toarray()[3], corpus_tv.toarray()[0]), \n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[3], corpus_tv.toarray()[1]),\n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[3], corpus_tv.toarray()[2]), scipy.spatial.distance.cosine(corpus_tv.toarray()[3], corpus_tv.toarray()[3]), \n",
    "                            scipy.spatial.distance.cosine(corpus_tv.toarray()[3], corpus_tv.toarray()[4])]}, index=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.884421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.846532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.952158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846532</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902903</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4\n",
       "1  0.000000  0.884421  1.000000  0.952158\n",
       "2  0.884421  0.000000  1.000000  1.000000\n",
       "3  1.000000  1.000000  0.000000  0.846532\n",
       "4  0.952158  1.000000  0.846532  0.000000\n",
       "5  1.000000  0.902903  1.000000  1.000000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_3_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
